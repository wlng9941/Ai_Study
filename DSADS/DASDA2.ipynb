{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151acd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from keras.models import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import concatenate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67188b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\procns\\AppData\\Local\\Temp\\ipykernel_6132\\1340352067.py:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv('C:/Users/procns/Desktop/인공지능/HAR/DSADS/DASDS_raw.csv', error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "#Load dataset and insert column names, remove the semicolon\n",
    "#Data preprocessing\n",
    "data = pd.read_csv('C:/Users/procns/Desktop/인공지능/HAR/DSADS/DASDS_raw.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64532a12",
   "metadata": {},
   "source": [
    "###  19 activities, 8 subject, 60 series -> 125 rows 45 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994be32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc</th>\n",
       "      <th>T_yacc</th>\n",
       "      <th>T_zacc</th>\n",
       "      <th>T_xgyro</th>\n",
       "      <th>T_ygyro</th>\n",
       "      <th>T_zgyro</th>\n",
       "      <th>T_xmag</th>\n",
       "      <th>T_ymag</th>\n",
       "      <th>T_zmag</th>\n",
       "      <th>RA_xacc</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_zacc</th>\n",
       "      <th>LL_xgyro</th>\n",
       "      <th>LL_ygyro</th>\n",
       "      <th>LL_zgyro</th>\n",
       "      <th>LL_xmag</th>\n",
       "      <th>LL_ymag</th>\n",
       "      <th>LL_zmag</th>\n",
       "      <th>activity</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.1305</td>\n",
       "      <td>1.0349</td>\n",
       "      <td>5.4217</td>\n",
       "      <td>-0.009461</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>-0.003424</td>\n",
       "      <td>-0.78712</td>\n",
       "      <td>-0.069654</td>\n",
       "      <td>0.15730</td>\n",
       "      <td>0.70097</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6220</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>-0.012092</td>\n",
       "      <td>-0.004457</td>\n",
       "      <td>0.74017</td>\n",
       "      <td>0.30053</td>\n",
       "      <td>-0.057730</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.1305</td>\n",
       "      <td>1.0202</td>\n",
       "      <td>5.3843</td>\n",
       "      <td>-0.009368</td>\n",
       "      <td>0.023485</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>-0.78717</td>\n",
       "      <td>-0.068275</td>\n",
       "      <td>0.15890</td>\n",
       "      <td>0.71829</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6218</td>\n",
       "      <td>-0.014784</td>\n",
       "      <td>-0.016477</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.73937</td>\n",
       "      <td>0.30183</td>\n",
       "      <td>-0.057514</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1604</td>\n",
       "      <td>1.0201</td>\n",
       "      <td>5.3622</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>-0.78664</td>\n",
       "      <td>-0.068277</td>\n",
       "      <td>0.15879</td>\n",
       "      <td>0.69849</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6366</td>\n",
       "      <td>-0.012770</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>-0.007918</td>\n",
       "      <td>0.73955</td>\n",
       "      <td>0.30052</td>\n",
       "      <td>-0.057219</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.1603</td>\n",
       "      <td>1.0052</td>\n",
       "      <td>5.3770</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>0.005649</td>\n",
       "      <td>-0.78529</td>\n",
       "      <td>-0.069849</td>\n",
       "      <td>0.15912</td>\n",
       "      <td>0.72799</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6070</td>\n",
       "      <td>-0.005725</td>\n",
       "      <td>0.009620</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.74029</td>\n",
       "      <td>0.30184</td>\n",
       "      <td>-0.057750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.1605</td>\n",
       "      <td>1.0275</td>\n",
       "      <td>5.3473</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>-0.005346</td>\n",
       "      <td>-0.78742</td>\n",
       "      <td>-0.068796</td>\n",
       "      <td>0.15916</td>\n",
       "      <td>0.71572</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6218</td>\n",
       "      <td>-0.003929</td>\n",
       "      <td>-0.008371</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.73845</td>\n",
       "      <td>0.30090</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>7.8015</td>\n",
       "      <td>1.3138</td>\n",
       "      <td>5.8588</td>\n",
       "      <td>-0.002519</td>\n",
       "      <td>0.017479</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>-0.79434</td>\n",
       "      <td>-0.077437</td>\n",
       "      <td>0.11570</td>\n",
       "      <td>0.30175</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6304</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>-0.003629</td>\n",
       "      <td>0.74160</td>\n",
       "      <td>0.30357</td>\n",
       "      <td>-0.057071</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>7.7867</td>\n",
       "      <td>1.3140</td>\n",
       "      <td>5.8213</td>\n",
       "      <td>-0.018844</td>\n",
       "      <td>0.010386</td>\n",
       "      <td>-0.002498</td>\n",
       "      <td>-0.79453</td>\n",
       "      <td>-0.076756</td>\n",
       "      <td>0.11461</td>\n",
       "      <td>0.32389</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6380</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.007593</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.73980</td>\n",
       "      <td>0.30381</td>\n",
       "      <td>-0.056066</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>7.7868</td>\n",
       "      <td>1.3141</td>\n",
       "      <td>5.7990</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.022728</td>\n",
       "      <td>-0.004341</td>\n",
       "      <td>-0.79326</td>\n",
       "      <td>-0.077579</td>\n",
       "      <td>0.11575</td>\n",
       "      <td>0.34342</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6229</td>\n",
       "      <td>-0.004479</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.009026</td>\n",
       "      <td>0.74021</td>\n",
       "      <td>0.30223</td>\n",
       "      <td>-0.056156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>7.8015</td>\n",
       "      <td>1.2991</td>\n",
       "      <td>5.8214</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>-0.006066</td>\n",
       "      <td>-0.79301</td>\n",
       "      <td>-0.076274</td>\n",
       "      <td>0.11548</td>\n",
       "      <td>0.34336</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6225</td>\n",
       "      <td>-0.004185</td>\n",
       "      <td>0.012646</td>\n",
       "      <td>-0.010807</td>\n",
       "      <td>0.74017</td>\n",
       "      <td>0.30302</td>\n",
       "      <td>-0.056573</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>7.8167</td>\n",
       "      <td>1.3288</td>\n",
       "      <td>5.7694</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>-0.004335</td>\n",
       "      <td>-0.79541</td>\n",
       "      <td>-0.077555</td>\n",
       "      <td>0.11566</td>\n",
       "      <td>0.31398</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6232</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>-0.017215</td>\n",
       "      <td>0.73948</td>\n",
       "      <td>0.30383</td>\n",
       "      <td>-0.058613</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc  T_yacc  T_zacc   T_xgyro   T_ygyro   T_zgyro   T_xmag    T_ymag  \\\n",
       "0     8.1305  1.0349  5.4217 -0.009461  0.001915 -0.003424 -0.78712 -0.069654   \n",
       "1     8.1305  1.0202  5.3843 -0.009368  0.023485  0.001953 -0.78717 -0.068275   \n",
       "2     8.1604  1.0201  5.3622  0.015046  0.014330  0.000204 -0.78664 -0.068277   \n",
       "3     8.1603  1.0052  5.3770  0.006892  0.018045  0.005649 -0.78529 -0.069849   \n",
       "4     8.1605  1.0275  5.3473  0.008811  0.030433 -0.005346 -0.78742 -0.068796   \n",
       "...      ...     ...     ...       ...       ...       ...      ...       ...   \n",
       "3595  7.8015  1.3138  5.8588 -0.002519  0.017479 -0.000679 -0.79434 -0.077437   \n",
       "3596  7.7867  1.3140  5.8213 -0.018844  0.010386 -0.002498 -0.79453 -0.076756   \n",
       "3597  7.7868  1.3141  5.7990  0.006585  0.022728 -0.004341 -0.79326 -0.077579   \n",
       "3598  7.8015  1.2991  5.8214  0.010103  0.001177 -0.006066 -0.79301 -0.076274   \n",
       "3599  7.8167  1.3288  5.7694  0.001140  0.020077 -0.004335 -0.79541 -0.077555   \n",
       "\n",
       "       T_zmag  RA_xacc  ...  LL_zacc  LL_xgyro  LL_ygyro  LL_zgyro  LL_xmag  \\\n",
       "0     0.15730  0.70097  ...   2.6220 -0.000232 -0.012092 -0.004457  0.74017   \n",
       "1     0.15890  0.71829  ...   2.6218 -0.014784 -0.016477  0.002789  0.73937   \n",
       "2     0.15879  0.69849  ...   2.6366 -0.012770  0.005717 -0.007918  0.73955   \n",
       "3     0.15912  0.72799  ...   2.6070 -0.005725  0.009620  0.006555  0.74029   \n",
       "4     0.15916  0.71572  ...   2.6218 -0.003929 -0.008371  0.002816  0.73845   \n",
       "...       ...      ...  ...      ...       ...       ...       ...      ...   \n",
       "3595  0.11570  0.30175  ...   2.6304  0.005635  0.009238 -0.003629  0.74160   \n",
       "3596  0.11461  0.32389  ...   2.6380  0.006434  0.007593  0.003591  0.73980   \n",
       "3597  0.11575  0.34342  ...   2.6229 -0.004479  0.004084  0.009026  0.74021   \n",
       "3598  0.11548  0.34336  ...   2.6225 -0.004185  0.012646 -0.010807  0.74017   \n",
       "3599  0.11566  0.31398  ...   2.6232  0.004912  0.007162 -0.017215  0.73948   \n",
       "\n",
       "      LL_ymag   LL_zmag  activity  subject_id  segments  \n",
       "0     0.30053 -0.057730         1           1         1  \n",
       "1     0.30183 -0.057514         1           1         1  \n",
       "2     0.30052 -0.057219         1           1         1  \n",
       "3     0.30184 -0.057750         1           1         1  \n",
       "4     0.30090 -0.057527         1           1         1  \n",
       "...       ...       ...       ...         ...       ...  \n",
       "3595  0.30357 -0.057071         1           1        29  \n",
       "3596  0.30381 -0.056066         1           1        29  \n",
       "3597  0.30223 -0.056156         1           1        29  \n",
       "3598  0.30302 -0.056573         1           1        29  \n",
       "3599  0.30383 -0.058613         1           1        29  \n",
       "\n",
       "[3600 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3fa372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1140000 entries, 0 to 1139999\n",
      "Data columns (total 48 columns):\n",
      " #   Column      Non-Null Count    Dtype  \n",
      "---  ------      --------------    -----  \n",
      " 0   T_xacc      1140000 non-null  float64\n",
      " 1   T_yacc      1140000 non-null  float64\n",
      " 2   T_zacc      1140000 non-null  float64\n",
      " 3   T_xgyro     1140000 non-null  float64\n",
      " 4   T_ygyro     1140000 non-null  float64\n",
      " 5   T_zgyro     1140000 non-null  float64\n",
      " 6   T_xmag      1140000 non-null  float64\n",
      " 7   T_ymag      1140000 non-null  float64\n",
      " 8   T_zmag      1140000 non-null  float64\n",
      " 9   RA_xacc     1140000 non-null  float64\n",
      " 10  RA_yacc     1140000 non-null  float64\n",
      " 11  RA_zacc     1140000 non-null  float64\n",
      " 12  RA_xgyro    1140000 non-null  float64\n",
      " 13  RA_ygyro    1140000 non-null  float64\n",
      " 14  RA_zgyro    1140000 non-null  float64\n",
      " 15  RA_xmag     1140000 non-null  float64\n",
      " 16  RA_ymag     1140000 non-null  float64\n",
      " 17  RA_zmag     1140000 non-null  float64\n",
      " 18  LA_xacc     1140000 non-null  float64\n",
      " 19  LA_yacc     1140000 non-null  float64\n",
      " 20  LA_zacc     1140000 non-null  float64\n",
      " 21  LA_xgyro    1140000 non-null  float64\n",
      " 22  LA_ygyro    1140000 non-null  float64\n",
      " 23  LA_zgyro    1140000 non-null  float64\n",
      " 24  LA_xmag     1140000 non-null  float64\n",
      " 25  LA_ymag     1140000 non-null  float64\n",
      " 26  LA_zmag     1140000 non-null  float64\n",
      " 27  RL_xacc     1140000 non-null  float64\n",
      " 28  RL_yacc     1140000 non-null  float64\n",
      " 29  RL_zacc     1140000 non-null  float64\n",
      " 30  RL_xgyro    1140000 non-null  float64\n",
      " 31  RL_ygyro    1140000 non-null  float64\n",
      " 32  RL_zgyro    1140000 non-null  float64\n",
      " 33  RL_xmag     1140000 non-null  float64\n",
      " 34  RL_ymag     1140000 non-null  float64\n",
      " 35  RL_zmag     1140000 non-null  float64\n",
      " 36  LL_xacc     1140000 non-null  float64\n",
      " 37  LL_yacc     1140000 non-null  float64\n",
      " 38  LL_zacc     1140000 non-null  float64\n",
      " 39  LL_xgyro    1140000 non-null  float64\n",
      " 40  LL_ygyro    1140000 non-null  float64\n",
      " 41  LL_zgyro    1140000 non-null  float64\n",
      " 42  LL_xmag     1140000 non-null  float64\n",
      " 43  LL_ymag     1140000 non-null  float64\n",
      " 44  LL_zmag     1140000 non-null  float64\n",
      " 45  activity    1140000 non-null  int64  \n",
      " 46  subject_id  1140000 non-null  int64  \n",
      " 47  segments    1140000 non-null  int64  \n",
      "dtypes: float64(45), int64(3)\n",
      "memory usage: 417.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f973e6c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_xacc',\n",
       " 'T_yacc',\n",
       " 'T_zacc',\n",
       " 'T_xgyro',\n",
       " 'T_ygyro',\n",
       " 'T_zgyro',\n",
       " 'T_xmag',\n",
       " 'T_ymag',\n",
       " 'T_zmag',\n",
       " 'RA_xacc',\n",
       " 'RA_yacc',\n",
       " 'RA_zacc',\n",
       " 'RA_xgyro',\n",
       " 'RA_ygyro',\n",
       " 'RA_zgyro',\n",
       " 'RA_xmag',\n",
       " 'RA_ymag',\n",
       " 'RA_zmag',\n",
       " 'LA_xacc',\n",
       " 'LA_yacc',\n",
       " 'LA_zacc',\n",
       " 'LA_xgyro',\n",
       " 'LA_ygyro',\n",
       " 'LA_zgyro',\n",
       " 'LA_xmag',\n",
       " 'LA_ymag',\n",
       " 'LA_zmag',\n",
       " 'RL_xacc',\n",
       " 'RL_yacc',\n",
       " 'RL_zacc',\n",
       " 'RL_xgyro',\n",
       " 'RL_ygyro',\n",
       " 'RL_zgyro',\n",
       " 'RL_xmag',\n",
       " 'RL_ymag',\n",
       " 'RL_zmag',\n",
       " 'LL_xacc',\n",
       " 'LL_yacc',\n",
       " 'LL_zacc',\n",
       " 'LL_xgyro',\n",
       " 'LL_ygyro',\n",
       " 'LL_zgyro',\n",
       " 'LL_xmag',\n",
       " 'LL_ymag',\n",
       " 'LL_zmag']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = []\n",
    "units = [\"T\",\"RA\",\"LA\",\"RL\",\"LL\"]\n",
    "movs = [\"acc\",\"gyro\",\"mag\"]\n",
    "axises = [\"x\",\"y\",\"z\"]\n",
    "\n",
    "#Creating the columns names\n",
    "def create_data_col():\n",
    "    for unit in units :\n",
    "        for mov in movs :\n",
    "            for axis in axises :\n",
    "                name_col = \"{}_{}{}\".format(unit, axis, mov)\n",
    "                columns.append(name_col)\n",
    "                \n",
    "create_data_col()\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68744c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 subject는 125개의 timestamps 데이터 60개를 19개 행동마다 가지고 있다\n",
    "# shape는 (-1, 100, 45 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7897a355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    142500\n",
       "2    142500\n",
       "3    142500\n",
       "4    142500\n",
       "5    142500\n",
       "6    142500\n",
       "7    142500\n",
       "8    142500\n",
       "Name: subject_id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.subject_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c03b2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_PERIODS = 125\n",
    "# The steps to take from one segment to the next; if this value is equal to TIME_PERIODS, then there is\n",
    "# no overlap between the segments\n",
    "STEP_DISTANCE = 125\n",
    "LABEL = 'activity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cd85408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc</th>\n",
       "      <th>T_yacc</th>\n",
       "      <th>T_zacc</th>\n",
       "      <th>T_xgyro</th>\n",
       "      <th>T_ygyro</th>\n",
       "      <th>T_zgyro</th>\n",
       "      <th>T_xmag</th>\n",
       "      <th>T_ymag</th>\n",
       "      <th>T_zmag</th>\n",
       "      <th>RA_xacc</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_zacc</th>\n",
       "      <th>LL_xgyro</th>\n",
       "      <th>LL_ygyro</th>\n",
       "      <th>LL_zgyro</th>\n",
       "      <th>LL_xmag</th>\n",
       "      <th>LL_ymag</th>\n",
       "      <th>LL_zmag</th>\n",
       "      <th>activity</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.086777</td>\n",
       "      <td>0.025233</td>\n",
       "      <td>0.044982</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>-0.770553</td>\n",
       "      <td>-0.067566</td>\n",
       "      <td>0.163278</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043006</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.001356</td>\n",
       "      <td>-0.000627</td>\n",
       "      <td>0.538658</td>\n",
       "      <td>0.241080</td>\n",
       "      <td>-0.055371</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.086777</td>\n",
       "      <td>0.024875</td>\n",
       "      <td>0.044672</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-0.770602</td>\n",
       "      <td>-0.066229</td>\n",
       "      <td>0.164938</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>-0.000772</td>\n",
       "      <td>-0.001848</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.538076</td>\n",
       "      <td>0.242123</td>\n",
       "      <td>-0.055164</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.087096</td>\n",
       "      <td>0.024873</td>\n",
       "      <td>0.044489</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.770083</td>\n",
       "      <td>-0.066230</td>\n",
       "      <td>0.164824</td>\n",
       "      <td>0.009748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043246</td>\n",
       "      <td>-0.000667</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>-0.001114</td>\n",
       "      <td>0.538207</td>\n",
       "      <td>0.241072</td>\n",
       "      <td>-0.054881</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.087095</td>\n",
       "      <td>0.024509</td>\n",
       "      <td>0.044611</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>-0.768762</td>\n",
       "      <td>-0.067755</td>\n",
       "      <td>0.165167</td>\n",
       "      <td>0.010160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042760</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.538745</td>\n",
       "      <td>0.242131</td>\n",
       "      <td>-0.055390</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087097</td>\n",
       "      <td>0.025053</td>\n",
       "      <td>0.044365</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>-0.000278</td>\n",
       "      <td>-0.770847</td>\n",
       "      <td>-0.066734</td>\n",
       "      <td>0.165208</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.537406</td>\n",
       "      <td>0.241377</td>\n",
       "      <td>-0.055176</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_xacc    T_yacc    T_zacc   T_xgyro   T_ygyro   T_zgyro    T_xmag  \\\n",
       "0  0.086777  0.025233  0.044982 -0.000342  0.000133 -0.000178 -0.770553   \n",
       "1  0.086777  0.024875  0.044672 -0.000339  0.001633  0.000101 -0.770602   \n",
       "2  0.087096  0.024873  0.044489  0.000544  0.000997  0.000011 -0.770083   \n",
       "3  0.087095  0.024509  0.044611  0.000249  0.001255  0.000293 -0.768762   \n",
       "4  0.087097  0.025053  0.044365  0.000318  0.002116 -0.000278 -0.770847   \n",
       "\n",
       "     T_ymag    T_zmag   RA_xacc  ...   LL_zacc  LL_xgyro  LL_ygyro  LL_zgyro  \\\n",
       "0 -0.067566  0.163278  0.009783  ...  0.043006 -0.000012 -0.001356 -0.000627   \n",
       "1 -0.066229  0.164938  0.010025  ...  0.043003 -0.000772 -0.001848  0.000392   \n",
       "2 -0.066230  0.164824  0.009748  ...  0.043246 -0.000667  0.000641 -0.001114   \n",
       "3 -0.067755  0.165167  0.010160  ...  0.042760 -0.000299  0.001079  0.000922   \n",
       "4 -0.066734  0.165208  0.009989  ...  0.043003 -0.000205 -0.000939  0.000396   \n",
       "\n",
       "    LL_xmag   LL_ymag   LL_zmag  activity  subject_id  segments  \n",
       "0  0.538658  0.241080 -0.055371         1           1         1  \n",
       "1  0.538076  0.242123 -0.055164         1           1         1  \n",
       "2  0.538207  0.241072 -0.054881         1           1         1  \n",
       "3  0.538745  0.242131 -0.055390         1           1         1  \n",
       "4  0.537406  0.241377 -0.055176         1           1         1  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in columns:\n",
    "        #data[column] = (data[column] - np.mean(data[column])) / np.std(data[column])\n",
    "        data[column] = data[column] / data[column].max()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b5728f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data[data['subject_id'] < 7]\n",
    "df_test = data[data['subject_id'] >=7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af1f9891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((285000, 48), (855000, 48))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "656b7283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\procns\\AppData\\Local\\Temp\\ipykernel_6132\\3525974209.py:13: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  label = stats.mode(data[label_name][i: i + time_steps])[0][0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped_segments shape :  (6839, 125, 45)\n",
      "labels shape : (6839,)\n",
      "reshaped_segments shape :  (2279, 125, 45)\n",
      "labels shape : (2279,)\n"
     ]
    }
   ],
   "source": [
    "def create_segments_and_labels(data, time_steps, step, label_name, columns):\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    columns = columns\n",
    "    N_FEATURES = len(columns)\n",
    "    # make segments\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(data) - time_steps, step):\n",
    "        segment = []\n",
    "        for column in columns:\n",
    "            segment.append(data[column].values[i: i + time_steps])\n",
    "        segments.append(segment)\n",
    "        label = stats.mode(data[label_name][i: i + time_steps])[0][0]\n",
    "        labels.append(label)\n",
    "    segments = np.asarray(segments, dtype= np.float32)\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    print('reshaped_segments shape : ', reshaped_segments.shape)\n",
    "    labels = np.asarray(labels)\n",
    "    print('labels shape :', labels.shape)\n",
    "    return reshaped_segments, labels\n",
    "\n",
    "X_train, y_train = create_segments_and_labels(df_train, TIME_PERIODS, STEP_DISTANCE, LABEL, columns)\n",
    "X_test, y_test = create_segments_and_labels(df_test, TIME_PERIODS, STEP_DISTANCE, LABEL, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa64711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")\n",
    "y_train = y_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85dc89ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6839, 125, 45) (6839, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\procns\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_train =  y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown = \"ignore\", sparse = False)\n",
    "enc = enc.fit(y_train)\n",
    "\n",
    "y_train = enc.transform(y_train)\n",
    "y_test = enc.transform(y_test)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e97a3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoch 500\n",
    "\n",
    "verbose,epochs,batch_size=1,10,32 \n",
    "n_timesteps,n_features,n_outputs=X_train.shape[1],X_train.shape[2],y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06d232c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b35b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "707b1c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "214/214 [==============================] - 7s 24ms/step - loss: 0.4785 - accuracy: 0.8533\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 5s 23ms/step - loss: 0.0983 - accuracy: 0.9659\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 5s 21ms/step - loss: 0.0676 - accuracy: 0.9782\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 4s 21ms/step - loss: 0.0477 - accuracy: 0.9829\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 5s 22ms/step - loss: 0.0375 - accuracy: 0.9871\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 5s 23ms/step - loss: 0.0274 - accuracy: 0.9905\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 5s 22ms/step - loss: 0.0307 - accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 5s 22ms/step - loss: 0.0320 - accuracy: 0.9895\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 5s 22ms/step - loss: 0.0469 - accuracy: 0.9854\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 5s 23ms/step - loss: 0.0207 - accuracy: 0.9934\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 123, 64)           8704      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 121, 64)           12352     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 121, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 60, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3840)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               384100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 19)                1919      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,075\n",
      "Trainable params: 407,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=epochs,batch_size=batch_size,verbose=verbose)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f62377d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 7ms/step - loss: 0.7052 - accuracy: 0.8907\n",
      "Accuracy >89.074153\n",
      "Base Loss >0.71\n"
     ]
    }
   ],
   "source": [
    "base_loss,base_accuracy=model.evaluate(X_test,y_test,batch_size=batch_size,verbose=1)\n",
    "\n",
    "#cnn_file='CNN_Model.h5'\n",
    "#tf.keras.models.save_model(model, cnn_file, include_optimizer=False)\n",
    "#print('model saved at ', cnn_file)\n",
    "#score,keras_file=evaluate_model(trainX,trainy,testX,testy)\n",
    "score=base_accuracy*100\n",
    "print('Accuracy >{:f}'.format(score))\n",
    "print('Base Loss >{:.2f}'.format(base_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c7e559",
   "metadata": {},
   "source": [
    "# 함수 사용하여 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b650642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    TIME_PERIODS = 100\n",
    "    STEP_DISTANCE = 50\n",
    "    LABEL = 'activity'\n",
    "    \n",
    "    columns = []\n",
    "    units = [\"T\",\"RA\",\"LA\",\"RL\",\"LL\"]\n",
    "    movs = [\"acc\",\"gyro\",\"mag\"]\n",
    "    axises = [\"x\",\"y\",\"z\"]\n",
    "\n",
    "    for unit in units :\n",
    "        for mov in movs :\n",
    "            for axis in axises :\n",
    "                name_col = \"{}_{}{}\".format(unit, axis, mov)\n",
    "                columns.append(name_col)\n",
    "    #Load dataset and insert column names, remove the semicolon\n",
    "    #Data preprocessing\n",
    "    data = pd.read_csv('C:/Users/procns/Desktop/인공지능/HAR/DSADS/DASDS_raw.csv', error_bad_lines=False)         \n",
    "    #data scaling ( 0 ~ 1)\n",
    "    data = scaler(data, columns)\n",
    "    \n",
    "    df_train = data[data['subject_id'] < 7]\n",
    "    df_test = data[data['subject_id'] >=7]\n",
    "    \n",
    "    X_train, y_train = create_segments_and_labels(df_train, TIME_PERIODS, STEP_DISTANCE, LABEL, columns)\n",
    "    X_test, y_test = create_segments_and_labels(df_test, TIME_PERIODS, STEP_DISTANCE, LABEL, columns)\n",
    "    \n",
    "    y_train, y_test  = onehotencoding_data(y_train, y_test)\n",
    "    print(\"X_train.shape :\", X_train.shape)\n",
    "    print(\"y_train.shape :\", y_train.shape)\n",
    "    print(\"X_test.shape:\", X_test.shape) \n",
    "    print(\"y_test.shape:\", y_test.shape)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b52525df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(data, columns):\n",
    "    for column in columns:\n",
    "        #data[column] = (data[column] - np.mean(data[column])) / np.std(data[column])\n",
    "        data[column] = data[column] / data[column].max()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3031be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segments_and_labels(data, time_steps, step, label_name, columns):\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    columns = columns\n",
    "    N_FEATURES = len(columns)\n",
    "    # make segments\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(data) - time_steps, step):\n",
    "        segment = []\n",
    "        for column in columns:\n",
    "            segment.append(data[column].values[i: i + time_steps])\n",
    "        segments.append(segment)\n",
    "        label = stats.mode(data[label_name][i: i + time_steps])[0][0]\n",
    "        labels.append(label)\n",
    "    segments = np.asarray(segments, dtype= np.float32)\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    print('reshaped_segments shape : ', reshaped_segments.shape)\n",
    "    labels = np.asarray(labels)\n",
    "    print('labels shape :', labels.shape)\n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6375cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencoding_data(train, test):\n",
    "    train =  train.reshape(-1,1)\n",
    "    test = test.reshape(-1,1)\n",
    "    enc = OneHotEncoder(handle_unknown = \"ignore\", sparse = False)\n",
    "    enc = enc.fit(train)\n",
    "\n",
    "    train = enc.transform(train)\n",
    "    test = enc.transform(test)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6f969bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    " verbose, epochs, batch_size = 0, 20, 32\n",
    " n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    " model = Sequential()\n",
    " model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    " model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(MaxPooling1D(pool_size=2))\n",
    " model.add(Flatten())\n",
    " model.add(Dense(100, activation='relu'))\n",
    " model.add(Dense(n_outputs, activation='softmax'))\n",
    " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " # fit network\n",
    " model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    " # evaluate model\n",
    " _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    " return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99c1cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa9269a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy = load_dataset()\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d5d6c4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\procns\\AppData\\Local\\Temp\\ipykernel_13876\\4049903537.py:18: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv('C:/Users/procns/Desktop/인공지능/HAR/DSADS/DASDS_raw.csv', error_bad_lines=False)\n",
      "C:\\Users\\procns\\AppData\\Local\\Temp\\ipykernel_13876\\1722284917.py:13: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  label = stats.mode(data[label_name][i: i + time_steps])[0][0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped_segments shape :  (17098, 100, 45)\n",
      "labels shape : (17098,)\n",
      "reshaped_segments shape :  (5698, 100, 45)\n",
      "labels shape : (5698,)\n",
      "X_train.shape : (17098, 100, 45)\n",
      "y_train.shape : (17098, 19)\n",
      "X_test.shape: (5698, 100, 45)\n",
      "y_test.shape: (5698, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\procns\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">#1: 85.574\n",
      ">#2: 83.573\n",
      ">#3: 87.206\n",
      ">#4: 86.785\n",
      ">#5: 84.626\n",
      ">#6: 87.539\n",
      ">#7: 84.731\n",
      ">#8: 84.925\n",
      ">#9: 86.241\n",
      ">#10: 86.381\n",
      "[85.5738878250122, 83.57318639755249, 87.20603585243225, 86.78483963012695, 84.62618589401245, 87.5394880771637, 84.73148345947266, 84.92453694343567, 86.24078631401062, 86.38118505477905]\n",
      "Accuracy: 85.758% (+/-1.216)\n"
     ]
    }
   ],
   "source": [
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f744081b",
   "metadata": {},
   "source": [
    "# Number of Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dab4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy, n_filters):\n",
    " verbose, epochs, batch_size = 0, 10, 32\n",
    " n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    " model = Sequential()\n",
    " model.add(Conv1D(filters=n_filters, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    " model.add(Conv1D(filters=n_filters, kernel_size=3, activation='relu'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(MaxPooling1D(pool_size=2))\n",
    " model.add(Flatten())\n",
    " model.add(Dense(100, activation='relu'))\n",
    " model.add(Dense(n_outputs, activation='softmax'))\n",
    " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " # fit network\n",
    " model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    " # evaluate model\n",
    " _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    " return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "537a6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_results(scores, params):\n",
    " print(scores, params)\n",
    " # summarize mean and standard deviation\n",
    " for i in range(len(scores)):\n",
    "     m, s = mean(scores[i]), std(scores[i])\n",
    "     print('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    " # boxplot of scores\n",
    " pyplot.boxplot(scores, labels=params)\n",
    " #pyplot.savefig('exp_cnn_filters.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f710f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an experiment\n",
    "def run_experiment(params, repeats=10):\n",
    " # load data\n",
    " trainX, trainy, testX, testy = load_dataset()\n",
    " # test each parameter\n",
    " all_scores = list()\n",
    " for p in params:\n",
    "     # repeat experiment\n",
    "     scores = list()\n",
    "     for r in range(repeats):\n",
    "         score = evaluate_model(trainX, trainy, testX, testy, p)\n",
    "         score = score * 100.0\n",
    "         print('>p=%d #%d: %.3f' % (p, r+1, score))\n",
    "         scores.append(score)\n",
    "     all_scores.append(scores)\n",
    " # summarize results\n",
    " summarize_results(all_scores, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88f29973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\procns\\AppData\\Local\\Temp\\ipykernel_13876\\4049903537.py:18: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv('C:/Users/procns/Desktop/인공지능/HAR/DSADS/DASDS_raw.csv', error_bad_lines=False)\n",
      "C:\\Users\\procns\\AppData\\Local\\Temp\\ipykernel_13876\\1722284917.py:13: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  label = stats.mode(data[label_name][i: i + time_steps])[0][0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped_segments shape :  (17098, 100, 45)\n",
      "labels shape : (17098,)\n",
      "reshaped_segments shape :  (5698, 100, 45)\n",
      "labels shape : (5698,)\n",
      "X_train.shape : (17098, 100, 45)\n",
      "y_train.shape : (17098, 19)\n",
      "X_test.shape: (5698, 100, 45)\n",
      "y_test.shape: (5698, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\procns\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">p=8 #1: 87.224\n",
      ">p=8 #2: 87.136\n",
      ">p=8 #3: 82.362\n",
      ">p=8 #4: 84.819\n",
      ">p=8 #5: 85.188\n",
      ">p=8 #6: 80.432\n",
      ">p=8 #7: 85.732\n",
      ">p=8 #8: 86.416\n",
      ">p=8 #9: 82.555\n",
      ">p=8 #10: 86.135\n",
      ">p=16 #1: 87.610\n",
      ">p=16 #2: 86.100\n",
      ">p=16 #3: 84.328\n",
      ">p=16 #4: 86.715\n",
      ">p=16 #5: 88.119\n",
      ">p=16 #6: 83.468\n",
      ">p=16 #7: 85.451\n",
      ">p=16 #8: 85.732\n",
      ">p=16 #9: 88.189\n",
      ">p=16 #10: 87.066\n",
      ">p=32 #1: 86.171\n",
      ">p=32 #2: 86.697\n",
      ">p=32 #3: 85.065\n",
      ">p=32 #4: 78.256\n",
      ">p=32 #5: 84.258\n",
      ">p=32 #6: 86.083\n",
      ">p=32 #7: 86.276\n",
      ">p=32 #8: 87.855\n",
      ">p=32 #9: 84.872\n",
      ">p=32 #10: 85.714\n",
      ">p=64 #1: 87.048\n",
      ">p=64 #2: 85.065\n",
      ">p=64 #3: 83.380\n",
      ">p=64 #4: 84.100\n",
      ">p=64 #5: 83.714\n",
      ">p=64 #6: 88.031\n",
      ">p=64 #7: 85.293\n",
      ">p=64 #8: 87.680\n",
      ">p=64 #9: 84.187\n",
      ">p=64 #10: 88.821\n",
      ">p=128 #1: 82.380\n",
      ">p=128 #2: 84.223\n",
      ">p=128 #3: 86.925\n",
      ">p=128 #4: 84.679\n",
      ">p=128 #5: 86.732\n",
      ">p=128 #6: 86.065\n",
      ">p=128 #7: 86.925\n",
      ">p=128 #8: 83.012\n",
      ">p=128 #9: 88.277\n",
      ">p=128 #10: 85.381\n",
      ">p=256 #1: 85.609\n",
      ">p=256 #2: 81.537\n",
      ">p=256 #3: 83.187\n",
      ">p=256 #4: 83.398\n",
      ">p=256 #5: 87.206\n",
      ">p=256 #6: 88.382\n",
      ">p=256 #7: 81.625\n",
      ">p=256 #8: 88.206\n",
      ">p=256 #9: 81.257\n",
      ">p=256 #10: 86.732\n",
      "[[87.2235894203186, 87.13583946228027, 82.36223459243774, 84.81923341751099, 85.18778681755066, 80.43172955513, 85.73183417320251, 86.41628623008728, 82.55528211593628, 86.13548874855042], [87.60969042778015, 86.10038757324219, 84.32783484458923, 86.7146372795105, 88.11863660812378, 83.46788287162781, 85.45103669166565, 85.73183417320251, 88.18883895874023, 87.06563711166382], [86.17058396339417, 86.69708967208862, 85.0649356842041, 78.25552821159363, 84.25763249397278, 86.08283400535583, 86.27588748931885, 87.85538673400879, 84.87188220024109, 85.71428656578064], [87.04808950424194, 85.0649356842041, 83.38013291358948, 84.09968614578247, 83.71358513832092, 88.03088665008545, 85.29308438301086, 87.67988681793213, 84.1874361038208, 88.82063627243042], [82.37978219985962, 84.22253131866455, 86.92523837089539, 84.67883467674255, 86.73218488693237, 86.06528639793396, 86.92523837089539, 83.01158547401428, 88.27658891677856, 85.3808343410492], [85.60898303985596, 81.53738379478455, 83.18708539009094, 83.39768052101135, 87.20603585243225, 88.38188648223877, 81.62513375282288, 88.20638656616211, 81.2565803527832, 86.73218488693237]] [8, 16, 32, 64, 128, 256]\n",
      "Param=8: 84.800% (+/-2.164)\n",
      "Param=16: 86.278% (+/-1.495)\n",
      "Param=32: 85.125% (+/-2.482)\n",
      "Param=64: 85.732% (+/-1.888)\n",
      "Param=128: 85.460% (+/-1.784)\n",
      "Param=256: 84.714% (+/-2.690)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the experiment\n",
    "n_params = [8, 16, 32, 64, 128, 256]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b82e4",
   "metadata": {},
   "source": [
    "# Size of kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65962dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy, n_kernel):\n",
    " verbose, epochs, batch_size = 0, 15, 32\n",
    " n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    " model = Sequential()\n",
    " model.add(Conv1D(filters=64, kernel_size=n_kernel, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    " model.add(Conv1D(filters=64, kernel_size=n_kernel, activation='relu'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(MaxPooling1D(pool_size=2))\n",
    " model.add(Flatten())\n",
    " model.add(Dense(100, activation='relu'))\n",
    " model.add(Dense(n_outputs, activation='softmax'))\n",
    " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " # fit network\n",
    " model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    " # evaluate model\n",
    " _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    " return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "680da5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_results(scores, params):\n",
    " print(scores, params)\n",
    " # summarize mean and standard deviation\n",
    " for i in range(len(scores)):\n",
    "     m, s = mean(scores[i]), std(scores[i])\n",
    "     print('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    " # boxplot of scores\n",
    " pyplot.boxplot(scores, labels=params)\n",
    " #pyplot.savefig('exp_cnn_kernel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fef814ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an experiment\n",
    "def run_experiment(params, repeats=10):\n",
    " # load data\n",
    " trainX, trainy, testX, testy = load_dataset()\n",
    " # test each parameter\n",
    " all_scores = list()\n",
    " for p in params:\n",
    " # repeat experiment\n",
    "     scores = list()\n",
    "     for r in range(repeats):\n",
    "         score = evaluate_model(trainX, trainy, testX, testy, p)\n",
    "         score = score * 100.0\n",
    "         print('>p=%d #%d: %.3f' % (p, r+1, score))\n",
    "         scores.append(score)\n",
    "     all_scores.append(scores)\n",
    " # summarize results\n",
    " summarize_results(all_scores, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67a8e826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\procns\\AppData\\Local\\Temp\\ipykernel_13876\\4049903537.py:18: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv('C:/Users/procns/Desktop/인공지능/HAR/DSADS/DASDS_raw.csv', error_bad_lines=False)\n",
      "C:\\Users\\procns\\AppData\\Local\\Temp\\ipykernel_13876\\1722284917.py:13: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  label = stats.mode(data[label_name][i: i + time_steps])[0][0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped_segments shape :  (17098, 100, 45)\n",
      "labels shape : (17098,)\n",
      "reshaped_segments shape :  (5698, 100, 45)\n",
      "labels shape : (5698,)\n",
      "X_train.shape : (17098, 100, 45)\n",
      "y_train.shape : (17098, 19)\n",
      "X_test.shape: (5698, 100, 45)\n",
      "y_test.shape: (5698, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\procns\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">p=2 #1: 86.399\n",
      ">p=2 #2: 86.697\n",
      ">p=2 #3: 82.555\n",
      ">p=2 #4: 85.960\n",
      ">p=2 #5: 88.803\n",
      ">p=2 #6: 87.645\n",
      ">p=2 #7: 87.188\n",
      ">p=2 #8: 85.504\n",
      ">p=2 #9: 83.222\n",
      ">p=2 #10: 84.872\n",
      ">p=3 #1: 80.906\n",
      ">p=3 #2: 86.188\n",
      ">p=3 #3: 81.572\n",
      ">p=3 #4: 86.399\n",
      ">p=3 #5: 84.205\n",
      ">p=3 #6: 84.714\n",
      ">p=3 #7: 82.204\n",
      ">p=3 #8: 81.204\n",
      ">p=3 #9: 88.610\n",
      ">p=3 #10: 84.784\n",
      ">p=5 #1: 81.923\n",
      ">p=5 #2: 87.048\n",
      ">p=5 #3: 86.522\n",
      ">p=5 #4: 86.434\n",
      ">p=5 #5: 81.046\n",
      ">p=5 #6: 80.730\n",
      ">p=5 #7: 78.905\n",
      ">p=5 #8: 85.679\n",
      ">p=5 #9: 82.380\n",
      ">p=5 #10: 81.432\n",
      ">p=7 #1: 82.713\n",
      ">p=7 #2: 83.626\n",
      ">p=7 #3: 82.959\n",
      ">p=7 #4: 81.906\n",
      ">p=7 #5: 86.522\n",
      ">p=7 #6: 81.748\n",
      ">p=7 #7: 86.416\n",
      ">p=7 #8: 84.907\n",
      ">p=7 #9: 85.065\n",
      ">p=7 #10: 83.836\n",
      ">p=11 #1: 73.833\n",
      ">p=11 #2: 78.501\n",
      ">p=11 #3: 78.308\n",
      ">p=11 #4: 74.500\n",
      ">p=11 #5: 78.098\n",
      ">p=11 #6: 78.729\n",
      ">p=11 #7: 74.605\n",
      ">p=11 #8: 74.026\n",
      ">p=11 #9: 77.764\n",
      ">p=11 #10: 77.694\n",
      "[[86.3987386226654, 86.69708967208862, 82.55528211593628, 85.95998883247375, 88.80308866500854, 87.6447856426239, 87.18848824501038, 85.50368547439575, 83.22218060493469, 84.87188220024109], [80.90558052062988, 86.18813753128052, 81.5724790096283, 86.3987386226654, 84.20498371124268, 84.71393585205078, 82.20428228378296, 81.2039315700531, 88.61004114151001, 84.78413224220276], [81.9234848022461, 87.04808950424194, 86.52158379554749, 86.43383383750916, 81.04597926139832, 80.73008060455322, 78.90487909317017, 85.67918539047241, 82.37978219985962, 81.43208026885986], [82.71323442459106, 83.62583518028259, 82.9589307308197, 81.90593123435974, 86.52158379554749, 81.74797892570496, 86.41628623008728, 84.90698337554932, 85.0649356842041, 83.83643627166748], [73.83292317390442, 78.50123047828674, 78.30817699432373, 74.49982166290283, 78.09757590293884, 78.7293791770935, 74.60512518882751, 74.02597665786743, 77.76412963867188, 77.69392728805542]] [2, 3, 5, 7, 11]\n",
      "Param=2: 85.885% (+/-1.833)\n",
      "Param=3: 84.079% (+/-2.437)\n",
      "Param=5: 83.210% (+/-2.776)\n",
      "Param=7: 83.970% (+/-1.628)\n",
      "Param=11: 76.606% (+/-1.963)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the experiment\n",
    "n_params = [2, 3, 5, 7, 11]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebffdfaf",
   "metadata": {},
   "source": [
    "# Multi-Headed Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c59ebba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    " verbose, epochs, batch_size = 0, 10, 32\n",
    " n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    " # head 1\n",
    " inputs1 = Input(shape=(n_timesteps,n_features))\n",
    " conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs1)\n",
    " drop1 = Dropout(0.5)(conv1)\n",
    " pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    " flat1 = Flatten()(pool1)\n",
    " # head 2\n",
    " inputs2 = Input(shape=(n_timesteps,n_features))\n",
    " conv2 = Conv1D(filters=64, kernel_size=5, activation='relu')(inputs2)\n",
    " drop2 = Dropout(0.5)(conv2)\n",
    " pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    " flat2 = Flatten()(pool2)\n",
    " # head 3\n",
    " inputs3 = Input(shape=(n_timesteps,n_features))\n",
    " conv3 = Conv1D(filters=64, kernel_size=11, activation='relu')(inputs3)\n",
    " drop3 = Dropout(0.5)(conv3)\n",
    " pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    " flat3 = Flatten()(pool3)\n",
    " # merge\n",
    " merged = concatenate([flat1, flat2, flat3])\n",
    " # interpretation\n",
    " dense1 = Dense(100, activation='relu')(merged)\n",
    " outputs = Dense(n_outputs, activation='softmax')(dense1)\n",
    " model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    " # save a plot of the model\n",
    " #plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    " plot_model(model, show_shapes=True)\n",
    " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " # fit network\n",
    " model.fit([trainX,trainX,trainX], trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    " # evaluate model\n",
    " _, accuracy = model.evaluate([testX,testX,testX], testy, batch_size=batch_size, verbose=0)\n",
    " return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24f49abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    " print(scores)\n",
    " m, s = mean(scores), std(scores)\n",
    " print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdef675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    " # load data\n",
    " trainX, trainy, testX, testy = load_dataset()\n",
    " # repeat experiment\n",
    " scores = list()\n",
    " for r in range(repeats):\n",
    "     score = evaluate_model(trainX, trainy, testX, testy)\n",
    "     score = score * 100.0\n",
    "     print('>#%d: %.3f' % (r+1, score))\n",
    "     scores.append(score)\n",
    " # summarize results\n",
    " summarize_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cec73316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\procns\\AppData\\Local\\Temp\\ipykernel_13876\\4049903537.py:18: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv('C:/Users/procns/Desktop/인공지능/HAR/DSADS/DASDS_raw.csv', error_bad_lines=False)\n",
      "C:\\Users\\procns\\AppData\\Local\\Temp\\ipykernel_13876\\1722284917.py:13: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  label = stats.mode(data[label_name][i: i + time_steps])[0][0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped_segments shape :  (17098, 100, 45)\n",
      "labels shape : (17098,)\n",
      "reshaped_segments shape :  (5698, 100, 45)\n",
      "labels shape : (5698,)\n",
      "X_train.shape : (17098, 100, 45)\n",
      "y_train.shape : (17098, 19)\n",
      "X_test.shape: (5698, 100, 45)\n",
      "y_test.shape: (5698, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\procns\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">#1: 86.522\n",
      ">#2: 87.996\n",
      ">#3: 84.802\n",
      ">#4: 85.118\n",
      ">#5: 84.731\n",
      ">#6: 85.258\n",
      ">#7: 81.064\n",
      ">#8: 82.257\n",
      ">#9: 80.379\n",
      ">#10: 83.556\n",
      "[86.52158379554749, 87.99578547477722, 84.80168581008911, 85.1175844669342, 84.73148345947266, 85.25798320770264, 81.06353282928467, 82.25693106651306, 80.3790807723999, 83.55563282966614]\n",
      "Accuracy: 84.168% (+/-2.259)\n"
     ]
    }
   ],
   "source": [
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530441b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
